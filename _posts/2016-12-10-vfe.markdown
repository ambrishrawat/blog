---
layout: post
title:  "Varitional Inference: A high-level overview"
date:   2016-12-10 22:56:35 +0000
categories: 
comments: true
---

Much to one’s surprise or delight, reasoning with assumptions can be achieved within the elegance of just two guiding rules - the sum and product rule of probability. Assumptions, opinions, approximate knowledge or beliefs - they are merely placeholders when viewed through the mathematical construct of uncertainty.  Uncertainty (or equivalently degree of belief) in the variability of x, is quantified as a real number through a function p(x). This function, by virtue of Cox’s axioms must uphold the rules of probability theory, and in particular, the sum and product rule.


Sum-rule: 

$$ p(AB|C) = p(A|BC)p(BC) $$ 

Product-rule: 

$$ p(AB) + p(\bar{A}|B) = 1 $$


Uncertainty has an all-pervasive presence in a statistical model - from noise in the observations, to a model’s belief about its parameters, to uncertainty in model predictions, to our belief about the model itself. But with its explicit and faithful representation in Bayesian probability theory, one can reason with it in a principled way.


Most ML tasks can be conveniently (and crudely) summarised as follows - a model, accompanied with its explicit and necessary assumptions based on prior knowledge, is capable of making predictions and performing inference in the light of observed data. In this simplistic pipeline, it is easy to examine how uncertainty factors in modelling tasks.


Uncertainty representation: All the the believed uncertainties in the mathematical description of a model are stated via functional definitions - prior p(θ|m), likelihood p(D|m), noise processes, among other expressions. 


Uncertainty propagation: Intuitively, uncertainty propagation is required at the stage of decision-making (computing utilities or parameter-setting), which in general translates to prediction or inference. Mathematically, this involves the use of marginalisation principle (a direct application of sum and product rule). 


Inference and Prediction: The task of inference or learning boils down to squeezing prior uncertainties (p(θ)) (often with respect to parameters, latent variables etc.) through the data (D) to posterior uncertainties (p(θ|D, m)) (following Bayes’ rule).


The normalisation constant, p(D|m) is referred to as Marginal Likelihood or Model Evidence. At the level of conditioning on m, Bayesian model selection is naturally implemented as Occam’s Razor. Moreover, these updated uncertainties in the posterior can be sequentially propagated while making predictions about the unobserved (new data, D∗).


The elegance of first principles makes Bayesian reasoning extremely compelling. However, the theory merely guides on what-to-do and often fails on the how-to front. This latter one is where the practicality and feasibility are challenged, or in other words computational and analytical intractability. And more often that what would expect, these computations are intractable. Therefore, in practice a range of approximations are used. The inexpensive
point estimates, being the most common ones where one settles for solutions from optimisation of maximum likelihood and maximum a posteriori. And then there are  deterministic approximations which harness structural understanding of the model like Variational mean field and Expectation Propagation.  Lastly, there are the computationally demanding but often asymptotically exact stochastic methods (like sampling).


Of these different approaches, I find Variational Inference the most interesting, for a few simple reasons.
It compromises the least on uncertainty representation. The apprxxomate posterior __ an analytical form.
It’s approach resemples statistcal physics as one can look at stastical propoerties in the norms of entropy proficency in dealing wuth statistical proporties of a system as well as the probablistic reasoning, where one could reason with the new approximate model, in same way as before.
The popular support it gathers from reducing the intractability to an optimisation problem


Variational Inference appends to the set of model assumptions, a parameterised approximate posterior (q()). Thus, it encourages you to search for the posterior in a smaller space of possible choices. A space spanned by the range of variational parameters. More importantly, the choice of approximate posterior is not arbitrary. The theory proposes another guiding principle - choose a distribution that most similar the exact posterior of the original model. Similarity, here, being measured via KL divergence. 

